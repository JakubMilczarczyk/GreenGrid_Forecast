# Development Environment Setup â€“ GGF Energy Demand Project

## Cel
Ten dokument opisuje, jak skonfigurowaÄ‡ i uruchomiÄ‡ Å›rodowisko deweloperskie projektu **GGF Energy Demand Prediction** od zera, korzystajÄ…c z Docker Compose.

---

## 1. Wymagania wstÄ™pne

Przed rozpoczÄ™ciem upewnij siÄ™, Å¼e masz zainstalowane:
- **Docker** â‰¥ 24.x
- **Docker Compose** (wbudowany w Docker CLI)
- **Git**
- **curl** (do testÃ³w API i pobierania plikÃ³w)
- **Python** â‰¥ 3.11 (opcjonalnie, jeÅ›li chcesz uruchamiaÄ‡ skrypty lokalnie)

---

## 2. Klonowanie repozytorium

```bash
git clone git@github.com:twoje/repo.git
cd repo
3. Plik .env
UtwÃ³rz plik .env w katalogu gÅ‚Ã³wnym projektu na podstawie szablonu .env.example:

```bash

cp .env.example .env
```
W pliku `.env` skonfiguruj:

ÅšcieÅ¼ki dla volumes (`DATA_DIR`, `MODELS_DIR`, `CONFIG_DIR`)

Uwierzytelnienia (np. `API keys`)

Parametry Airflow (opcjonalnie)

## Struktura katalogÃ³w
Twoje lokalne drzewo projektu powinno wyglÄ…daÄ‡ tak:

```arduino

.
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ plugins/
â”‚   â””â”€â”€ Dockerfile.airflow
â”œâ”€â”€ shared/
â”‚   â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ models/
â”‚   â””â”€â”€ config/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ services.md
â”‚   â”œâ”€â”€ readme_dev_setup.md
â”‚   â””â”€â”€ ...
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ .env
```
Uwaga: katalog shared/ jest montowany do kontenerÃ³w i wspÃ³Å‚dzielony miÄ™dzy usÅ‚ugami.

## Budowanie obrazÃ³w
```bash

docker compose build
```

## Inicjalizacja bazy Airflow
Wykonaj jednorazowo po pierwszym uruchomieniu:

```bash

docker compose up airflow-init
```

## Uruchamianie Å›rodowiska
Po zainicjalizowaniu bazy uruchom wszystkie usÅ‚ugi:

```bash

docker compose up -d
```

## UsÅ‚ugi i porty
- **Airflow Webserver:** http://localhost:8080
    Login: admin, HasÅ‚o: admin (domyÅ›lne w docker-compose.yml)

- **Postgres:** port `5432`

- **Redis:** port `6379`

- **(w przyszÅ‚oÅ›ci) Streamlit:** port `8501`

## Debugowanie
- **Logi konkretnej usÅ‚ugi:**

```bash

docker compose logs airflow-scheduler
docker compose logs airflow-worker
```

- **WejÅ›cie do kontenera Airflow:**

``bash

docker compose exec airflow-webserver
```

## Zatrzymywanie i czyszczenie
- **Zatrzymanie Å›rodowiska:**

```bash

docker compose down
```

**Zatrzymanie i usuniÄ™cie danych (peÅ‚ny reset):**

```bash

docker compose down -v
```

## Dalszy rozwÃ³j
Nowe DAG-i umieszczaj w `airflow/dags/`

Dane wejÅ›ciowe wrzucaj do `shared/data/`

Wyniki modeli i pipelineâ€™Ã³w zapisuj w `shared/models/`

Pliki konfiguracyjne przechowuj w `shared/config/`

ðŸ“Œ Tip: JeÅ¼eli zmieniasz pliki `.env` lub konfiguracjÄ™ `docker-compose.yml`, wykonaj:

```bash

docker compose down && docker compose up -d --build
```